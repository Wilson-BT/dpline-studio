# app home 地址
# APP_HOME=/Users/xxx/Documents/IdeaProjects/dpline-studio
# 数据临时目录位置
data.basedir.path=/tmp/dpline

# 远端地址 HDFS or S3 or NONE
resource.storage.type=S3

# if resource.storage.type=S3, the value like: s3a://dolphinscheduler;
# if resource.storage.type=HDFS and namenode HA is enabled, the value is hdfs://mycluster:8020, and you need to copy core-site.xml and hdfs-site.xml to conf dir
fs.defaultFS=s3a://flink
# 默认s3的endpoint
fs.s3a.endpoint=http://172.16.11.16:9000
# bucket 桶的名称
fs.s3a.bucketName=flink
# s3 key
fs.s3a.access.key=root
# s3 value
fs.s3a.secret.key=Root123456
# k8s本地节点的前缀，s3://test 映射到k8s宿主机本地，最后尽量是一个桶的名字，准备弃用
#k8s.local.path.prefix=/mnt/s3/flink
# operator的 netty通信地址，默认为localhost
operator.k8s.listen.host=127.0.0.1
# operator的 端口号
operator.k8s.listen.port=50055
# operator 的地址
operator.yarn.listen.host=127.0.0.1
# operator的 端口号
operator.yarn.listen.port=50055

#task.log.path=/tmp/dpline/

# hdfs dir config path
fs.hdfs.conf.dir=xxx

# prometheus 地址
monitor.prometheus.url=http://xxx:8000/d/wKbnD5Gnk/apache-flink-dashboard-for-job-task-manager?orgId=1&refresh=5s&var-datasource=Prometheus&var-job_name=%s